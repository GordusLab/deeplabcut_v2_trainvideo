{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9308e705",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SpiderCroppedVideoReader():\n",
    "    \"\"\" This class mimics OpenCV's VideoCapture class, but instead reads\n",
    "        the *.ufmf files, which contain 200x200 cropped/rotated and monochrome\n",
    "        spider images.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filename, progressCallback=None):\n",
    "        self.fname = filename\n",
    "        self.iframe = 0\n",
    "        self.progressCallback = progressCallback\n",
    "\n",
    "        # DEBUG\n",
    "        self.MAX_NUM_FRAMES = 50 * 3600 * 24 * 100\n",
    "\n",
    "        # Is this a supported input file?\n",
    "        if not self.fname.endswith('.ufmf'):\n",
    "            raise Exception('Unsupported input file. Only *.ufmf files allowed.')\n",
    "\n",
    "        # Open file to determine size\n",
    "        from motmot.SpiderMovie import SpiderMovie\n",
    "        mov = SpiderMovie(filename)\n",
    "        #self.arr = np.memmap(self.fname, dtype=np.uint8, mode='r')\n",
    "        #N = self.arr.shape[0]\n",
    "        N = mov.shape[0]*mov.shape[1]*mov.shape[2]\n",
    "        #del self.arr\n",
    "        # Ensure this file has the right size\n",
    "        if N % (1024 * 1024) != 0:\n",
    "            raise Exception('Image does not have expected size of 1024x1024.')\n",
    "        # Open again with right shape\n",
    "        #self.arr = np.memmap(self.fname, dtype=np.uint8, mode='r', shape=(int(N / (1024 * 1024)), 1024, 1024))\n",
    "        self.matrix_shape = mov.shape\n",
    "        self.mov = mov\n",
    "\n",
    "    def get_bbox(self):\n",
    "\n",
    "        return (0, self.mov.shape[1], 0, self.mov.shape[2])\n",
    "        \n",
    "    # Get various metadata\n",
    "    def get(self, i):\n",
    "        # Call progress callback\n",
    "        if self.progressCallback is not None:\n",
    "            try:\n",
    "                self.progressCallback(float(i) / self.matrix_shape[0])\n",
    "            except:\n",
    "                pass\n",
    "        # NUM. FRAMES\n",
    "        if i == 7:\n",
    "            if self.matrix_shape is not None:\n",
    "                return min(self.MAX_NUM_FRAMES, self.matrix_shape[0])\n",
    "            else:\n",
    "                raise Exception('File closed.')\n",
    "        # FPS\n",
    "        elif i == 5:\n",
    "            return 50\n",
    "        # HEIGHT\n",
    "        elif i == 4:\n",
    "            return 1024\n",
    "        # WIDTH\n",
    "        elif i == 3:\n",
    "            return 1024\n",
    "        # ERROR\n",
    "        else:\n",
    "            raise Exception('Unsupported metadata requested: {}'.format(i))\n",
    "\n",
    "    def isOpened(self):\n",
    "        return True\n",
    "\n",
    "    def read(self):\n",
    "        import numpy as np\n",
    "        if self.iframe >= self.get(7):\n",
    "            return False, np.zeros((1024, 1024), dtype=np.uint8)\n",
    "        else:\n",
    "            self.iframe += 1\n",
    "            return True, self.mov[self.iframe - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb543fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Z:/HsinYi/Test Video From Darya/test_clip_dlc_v2/raw\\\\bias_video_cam_2_date_2023_05_31_time_19_56_23_v001.all.s.ufmf']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direcory = 'Z:/HsinYi/Test Video From Darya/'\n",
    "project_folder = 'test_clip_dlc_v2/'\n",
    "basepath = direcory + project_folder\n",
    "project_name = 'TEST'\n",
    "scorer = 'PC'\n",
    "\n",
    "import os, glob\n",
    "\n",
    "\n",
    "video_list = glob.glob(os.path.join(basepath, 'raw/')+'*.s.ufmf')\n",
    "video_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93d14a65-0af8-481f-bae2-b5b7d382dcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "date= '2023-11-22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fd1b6c8-40d2-47fe-9342-642aa96d5cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = \"{pn}-{exp}-{date}\".format(pn=project_name, exp=scorer, date=date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7923636c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n",
      "Created \"\\\\10.99.66.32\\Team Spider\\HsinYi\\Test Video From Darya\\test_clip_dlc_v2\\TEST-PC-2023-11-22\\videos\"\n",
      "Created \"\\\\10.99.66.32\\Team Spider\\HsinYi\\Test Video From Darya\\test_clip_dlc_v2\\TEST-PC-2023-11-22\\labeled-data\"\n",
      "Created \"\\\\10.99.66.32\\Team Spider\\HsinYi\\Test Video From Darya\\test_clip_dlc_v2\\TEST-PC-2023-11-22\\training-datasets\"\n",
      "Created \"\\\\10.99.66.32\\Team Spider\\HsinYi\\Test Video From Darya\\test_clip_dlc_v2\\TEST-PC-2023-11-22\\dlc-models\"\n",
      "Copying the videos\n",
      "\\\\10.99.66.32\\Team Spider\\HsinYi\\Test Video From Darya\\test_clip_dlc_v2\\TEST-PC-2023-11-22\\videos\\bias_video_cam_2_date_2023_05_31_time_19_56_23_v001.all.s.ufmf\n",
      "Generated \"\\\\10.99.66.32\\Team Spider\\HsinYi\\Test Video From Darya\\test_clip_dlc_v2\\TEST-PC-2023-11-22\\config.yaml\"\n",
      "\n",
      "A new project with name TEST-PC-2023-11-22 is created at \\\\10.99.66.32\\Team Spider\\HsinYi\\Test Video From Darya\\test_clip_dlc_v2 and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gordus_Lab\\anaconda3\\envs\\napari_dlc_trainvideo\\Lib\\site-packages\\deeplabcut\\motmot\\ufmf\\ufmf.py:199: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  assert key not in value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\\\\\\\10.99.66.32\\\\Team Spider\\\\HsinYi\\\\Test Video From Darya\\\\test_clip_dlc_v2\\\\TEST-PC-2023-11-22\\\\config.yaml'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import deeplabcut\n",
    "deeplabcut.create_new_project(project_name , scorer, video_list, working_directory=basepath, copy_videos= True, videoReader = SpiderCroppedVideoReader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "742bc1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = basepath+ '/'+project+'/config.yaml'\n",
    "cfg = deeplabcut.auxiliaryfunctions.read_config(config_path)\n",
    "cfg['bodyparts'] =['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25']\n",
    "deeplabcut.auxiliaryfunctions.write_config(config_path, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d475914-8b23-4202-968e-1fb4c3083e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bias_video_cam_2_date_2023_05_31_time_19_56_23_v001.all.s.ufmf'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videoname = video_list[0].split('raw\\\\')[1]\n",
    "videoname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "643b5e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING-SOME LABELS FOR THE FRAMES\n"
     ]
    }
   ],
   "source": [
    "## Skip extract frames\n",
    "## Skip label frames\n",
    "\n",
    "## Generate labeling csv\n",
    "import os, glob\n",
    "\n",
    "videoname = video_list[0].split('raw\\\\')[1]\n",
    "joint_filename = basepath + '/croprot/' +videoname.replace('.ufmf','_dlc_abs.npy')\n",
    "\n",
    "from deeplabcut.generate_training_dataset import creating_labeling_csv\n",
    "creating_labeling_csv.creating_labeling_csv(config_path, basepath, videoname, joint_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab65e0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gordus_Lab\\anaconda3\\envs\\napari_dlc_trainvideo\\Lib\\site-packages\\deeplabcut\\motmot\\ufmf\\ufmf.py:199: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  assert key not in value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by PC.\n",
      "This is ufmf video. Randomly selected 25 images to plot.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 25/25 [00:10<00:00,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut\n",
    "deeplabcut.check_labels(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89342412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATING TRAININGSET\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/28914 [00:00<?, ?it/s]C:\\Users\\Gordus_Lab\\anaconda3\\envs\\napari_dlc_trainvideo\\Lib\\site-packages\\deeplabcut\\motmot\\ufmf\\ufmf.py:199: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  assert key not in value\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 28914/28914 [08:57<00:00, 53.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([19736, 20841, 22215, ...,  4317,  2514,  4756]),\n",
       "   array([ 4996,  7622,  6876, ..., 14816,  2448, 23582])))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"CREATING TRAININGSET\")\n",
    "deeplabcut.create_training_dataset(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3478912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0],\n",
      "                [1],\n",
      "                [2],\n",
      "                [3],\n",
      "                [4],\n",
      "                [5],\n",
      "                [6],\n",
      "                [7],\n",
      "                [8],\n",
      "                [9],\n",
      "                [10],\n",
      "                [11],\n",
      "                [12],\n",
      "                [13],\n",
      "                [14],\n",
      "                [15],\n",
      "                [16],\n",
      "                [17],\n",
      "                [18],\n",
      "                [19],\n",
      "                [20],\n",
      "                [21],\n",
      "                [22],\n",
      "                [23],\n",
      "                [24],\n",
      "                [25]],\n",
      " 'all_joints_names': ['0',\n",
      "                      '1',\n",
      "                      '2',\n",
      "                      '3',\n",
      "                      '4',\n",
      "                      '5',\n",
      "                      '6',\n",
      "                      '7',\n",
      "                      '8',\n",
      "                      '9',\n",
      "                      '10',\n",
      "                      '11',\n",
      "                      '12',\n",
      "                      '13',\n",
      "                      '14',\n",
      "                      '15',\n",
      "                      '16',\n",
      "                      '17',\n",
      "                      '18',\n",
      "                      '19',\n",
      "                      '20',\n",
      "                      '21',\n",
      "                      '22',\n",
      "                      '23',\n",
      "                      '24',\n",
      "                      '25'],\n",
      " 'alpha_r': 0.02,\n",
      " 'apply_prob': 0.5,\n",
      " 'batch_size': 1,\n",
      " 'clahe': True,\n",
      " 'claheratio': 0.1,\n",
      " 'crop_pad': 0,\n",
      " 'crop_sampling': 'hybrid',\n",
      " 'crop_size': [400, 400],\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_TESTNov22\\\\TEST_PC95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'decay_steps': 30000,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'edge': False,\n",
      " 'emboss': {'alpha': [0.0, 1.0], 'embossratio': 0.1, 'strength': [0.5, 1.5]},\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'histeq': True,\n",
      " 'histeqratio': 0.1,\n",
      " 'init_weights': 'C:\\\\Users\\\\Gordus_Lab\\\\anaconda3\\\\envs\\\\napari_dlc_trainvideo\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 1500,\n",
      " 'max_shift': 0.4,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_TESTNov22\\\\Documentation_data-TEST_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_stage': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 26,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'pre_resize': [],\n",
      " 'project_path': 'Z:/HsinYi/Test Video From '\n",
      "                 'Darya/test_clip_dlc_v2//TEST-PC-2023-11-22',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'sharpen': False,\n",
      " 'sharpenratio': 0.3,\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'Z:\\\\HsinYi\\\\Test Video From '\n",
      "                    'Darya\\\\test_clip_dlc_v2\\\\TEST-PC-2023-11-22\\\\dlc-models\\\\iteration-0\\\\TESTNov22-trainset95shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train the network\n",
      "Selecting single-animal trainer\n",
      "Batch Size is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gordus_Lab\\anaconda3\\envs\\napari_dlc_trainvideo\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ImageNet-pretrained resnet_50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Gordus_Lab\\anaconda3\\envs\\napari_dlc_trainvideo\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Gordus_Lab\\anaconda3\\envs\\napari_dlc_trainvideo\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\Gordus_Lab\\anaconda3\\envs\\napari_dlc_trainvideo\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\core\\train.py\", line 80, in load_and_enqueue\n",
      "    batch_np = dataset.next_batch()\n",
      "  File \"C:\\Users\\Gordus_Lab\\anaconda3\\envs\\napari_dlc_trainvideo\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\datasets\\pose_imgaug.py\", line 370, in next_batch\n",
      "    ) = self.get_batch()\n",
      "  File \"C:\\Users\\Gordus_Lab\\anaconda3\\envs\\napari_dlc_trainvideo\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\datasets\\pose_imgaug.py\", line 300, in get_batch\n",
      "    vid_name = self.cfg.project_path + '/videos/' + vid_name\n",
      "AttributeError: 'dict' object has no attribute 'project_path'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'Z:\\\\HsinYi\\\\Test Video From Darya\\\\test_clip_dlc_v2\\\\TEST-PC-2023-11-22\\\\dlc-models\\\\iteration-0\\\\TESTNov22-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24], [25]], 'all_joints_names': ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25'], 'alpha_r': 0.02, 'apply_prob': 0.5, 'clahe': True, 'claheratio': 0.1, 'crop_sampling': 'hybrid', 'crop_size': [400, 400], 'cropratio': 0.4, 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_TESTNov22\\\\TEST_PC95shuffle1.mat', 'decay_steps': 30000, 'display_iters': 1000, 'edge': False, 'emboss': {'alpha': [0.0, 1.0], 'embossratio': 0.1, 'strength': [0.5, 1.5]}, 'histeq': True, 'histeqratio': 0.1, 'init_weights': 'C:\\\\Users\\\\Gordus_Lab\\\\anaconda3\\\\envs\\\\napari_dlc_trainvideo\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt', 'lr_init': 0.0005, 'max_input_size': 1500, 'max_shift': 0.4, 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_TESTNov22\\\\Documentation_data-TEST_95shuffle1.pickle', 'min_input_size': 64, 'multi_stage': False, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 26, 'pos_dist_thresh': 17, 'pre_resize': [], 'project_path': 'Z:/HsinYi/Test Video From Darya/test_clip_dlc_v2//TEST-PC-2023-11-22', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'sharpen': False, 'sharpenratio': 0.3, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': (-90, 90)}}\n",
      "Starting training....\n"
     ]
    }
   ],
   "source": [
    "print('Train the network')\n",
    "deeplabcut.train_network(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bfbd2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  DLC_resnet50_TESTNov22shuffle1_50000  with # of training iterations: 50000\n",
      "This net has already been evaluated!\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut\n",
    "config_path = basepath+ '/'+project+'/config.yaml'\n",
    "cfg = deeplabcut.auxiliaryfunctions.read_config(config_path)\n",
    "\n",
    "deeplabcut.evaluate_network(\n",
    "    config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6994d170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-50000 for model Z:/HsinYi/Test Video From Darya/test_clip_dlc_v2//TEST-PC-2023-11-22\\dlc-models\\iteration-0\\TESTNov22-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gordus_Lab\\anaconda3\\envs\\napari_dlc_trainvideo\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "C:\\Users\\Gordus_Lab\\anaconda3\\envs\\napari_dlc_trainvideo\\Lib\\site-packages\\deeplabcut\\motmot\\ufmf\\ufmf.py:199: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  assert key not in value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  Z:/HsinYi/Test Video From Darya/test_clip_dlc_v2/TEST-PC-2023-11-22/videos/bias_video_cam_2_date_2023_05_31_time_19_56_23_v001.all.s.ufmf\n",
      "Loading  Z:/HsinYi/Test Video From Darya/test_clip_dlc_v2/TEST-PC-2023-11-22/videos/bias_video_cam_2_date_2023_05_31_time_19_56_23_v001.all.s.ufmf\n",
      "Duration of video [s]:  608.72 , recorded with  50 fps!\n",
      "Overall # of frames:  30436  found with (before cropping) frame dimensions:  1024 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30704it [12:38:15,  1.48s/it]                                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in Z:\\HsinYi\\Test Video From Darya\\test_clip_dlc_v2\\TEST-PC-2023-11-22\\videos...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet50_TESTNov22shuffle1_50000'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import deeplabcut\n",
    "videoname = 'bias_video_cam_2_date_2023_05_31_time_19_56_23_v001.all.s.ufmf'\n",
    "deeplabcut.analyze_videos(\n",
    "    config_path, videos=[basepath+project+'/videos/'+videoname], videoReader = SpiderCroppedVideoReader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93af68cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n",
      "Starting %  Z:\\HsinYi\\Test Video From Darya\\test_clip_dlc_v2\\TEST-PC-2023-11-22\\videos ['Z:/HsinYi/Test Video From Darya/test_clip_dlc_v2/TEST-PC-2023-11-22/videos/bias_video_cam_2_date_2023_05_31_time_19_56_23_v001.all.s.ufmf']\n",
      "Loading  Z:/HsinYi/Test Video From Darya/test_clip_dlc_v2/TEST-PC-2023-11-22/videos/bias_video_cam_2_date_2023_05_31_time_19_56_23_v001.all.s.ufmf and data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gordus_Lab\\anaconda3\\envs\\napari_dlc_trainvideo\\Lib\\site-packages\\deeplabcut\\motmot\\ufmf\\ufmf.py:199: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  assert key not in value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False 0 1024 0 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/3000 [00:00<?, ?it/s]C:\\Users\\Gordus_Lab\\anaconda3\\envs\\napari_dlc_trainvideo\\lib\\site-packages\\deeplabcut\\utils\\make_labeled_video.py:554: FutureWarning: `draw.circle` is deprecated in favor of `draw.disk`.`draw.circle` will be removed in version 0.19\n",
      "  rr, cc = circle(yc, xc, dotsize, shape=(ny, nx))\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 3000/3000 [00:40<00:00, 73.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing video...\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut\n",
    "config_path = basepath+ '/'+project+'/config.yaml'\n",
    "videoname = 'bias_video_cam_2_date_2023_05_31_time_19_56_23_v001.all.s.ufmf'\n",
    "## Note: Since I only train 1000 step, the video should look very bad.\n",
    "deeplabcut.create_labeled_ufmfvideo(config_path,[basepath+project+'/videos/'+videoname],videotype='ufmf',codec='mp4v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c974e63b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de5cf1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:napari_dlc_trainvideo]",
   "language": "python",
   "name": "conda-env-napari_dlc_trainvideo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
